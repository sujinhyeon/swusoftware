# gpt.py


import os
from dotenv import load_dotenv

load_dotenv()

# í™•ì¸ìš© ì¶œë ¥
print("ğŸ“ í˜„ì¬ ì‹¤í–‰ ë””ë ‰í† ë¦¬:", os.getcwd())
print("ğŸ§ª [DEBUG] API KEY:", os.getenv("OPENAI_API_KEY"))


# import os
# from dotenv import load_dotenv
# from openai import OpenAI

# # ğŸ” .envì—ì„œ í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
# load_dotenv()
# api_key = os.getenv("OPENAI_API_KEY")

# if not api_key:
#     raise ValueError("âŒ OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. .env ì„¤ì • í™•ì¸í•˜ì„¸ìš”.")

# client = OpenAI(api_key=api_key)

# def generate_family_question(family_info: dict, previous_answers: str = "") -> str:
#     prompt = f"""
#     ë‹¤ìŒì€ í•œ ê°€ì¡±ì˜ ì •ë³´ì•¼:
#     ì•„ë²„ì§€: {family_info.get("father", "")}
#     ì–´ë¨¸ë‹ˆ: {family_info.get("mother", "")}
#     ìë…€: {family_info.get("child", "")}

#     ìµœê·¼ ëŒ€í™” ë‚´ìš©:
#     {previous_answers}

#     ì´ ê°€ì¡±ì´ ì˜¤ëŠ˜ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•  ìˆ˜ ìˆë„ë¡
#     ë”°ëœ»í•˜ê³  ê³µê°í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì„ í•˜ë‚˜ë§Œ ë§Œë“¤ì–´ì¤˜.
#     """

#     response = client.chat.completions.create(
#         model="gpt-3.5-turbo",  # ë˜ëŠ” "gpt-4"
#         messages=[
#             {"role": "system", "content": "ë„ˆëŠ” ê°€ì¡± ê°„ ë”°ëœ»í•œ ëŒ€í™”ë¥¼ ì´ëŒì–´ì£¼ëŠ” AI ì±—ë´‡ì´ì•¼."},
#             {"role": "user", "content": prompt}
#         ],
#         temperature=0.8,
#         max_tokens=150
#     )

#     return response.choices[0].message.content
